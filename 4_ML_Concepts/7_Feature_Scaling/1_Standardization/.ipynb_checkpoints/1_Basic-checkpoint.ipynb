{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue\" align=\"center\"> Feature Scaling </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Types of Feature Scaling\n",
    "\n",
    " - MinMax Scalar\n",
    " \n",
    " \n",
    " - Standard Scalar\n",
    " \n",
    " \n",
    " - Normalize Data\n",
    " \n",
    " \n",
    " - Binarize Data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling:\n",
    "\n",
    "\n",
    "#### 1. **When we should apply Feature Scaling?**\n",
    "\n",
    "\n",
    "- Gradient Decent & Ecludian Concept  ---> Feature Scaling / Feature Normalisation should apply\n",
    "\n",
    "    1. Linear Regression (Gradient Decent --- Parabola curve)\n",
    "     \n",
    "    2. KNN\n",
    "     \n",
    "    3. K means clustering\n",
    "    \n",
    "    4. Hierarchical clustering\n",
    "    \n",
    "    5. Logistic Regression\n",
    "    \n",
    "    6. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **When we should not apply Feature Scaling?**\n",
    "\n",
    "\n",
    "- These are Ensemble technique. If you apply **Feature Scaling** also won't see any improvement.\n",
    "\n",
    "     1. Decision Tree\n",
    "     2. Random Forest\n",
    "     3. XG Boost\n",
    "     \n",
    "     \n",
    "- **Except Tree Based and Ensemble Algorithms,** for the rest it would be required. In Case of **CNN**, we do it differently as the value can be between 0 and 255 (pixels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\"> 1. Standardisation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=2mcEMRGW1eY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization:\n",
    "\n",
    "    \n",
    " 1. **Scale down** the values such that the **standardized values** should have a **mean zero and standard deviation 1.**\n",
    "    \n",
    "    \n",
    " 2. After standard scalar values **varies in between -1 to 1.**\n",
    "    \n",
    "    \n",
    " 3. For **target** feature not applied because it is **binary classification** ie \"0\" & \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of  Standardisation\n",
    "\n",
    "\n",
    "\n",
    "  1. **Standardisation (Z-Score Normalisation)**\n",
    "\n",
    "\n",
    "- Here all the features will be transformed in such a way that it will have the properties of a standard normal distribution with mean=0 and standard deviation=1\n",
    "\n",
    "\n",
    "- z= (x-mean)/standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 61], [0, 62], [1, 63], [1, 64]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[0,61],[0,62],[1,63],[1,64]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(data)             # calculate mean & standard deviation for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.34164079]\n",
      " [-1.         -0.4472136 ]\n",
      " [ 1.          0.4472136 ]\n",
      " [ 1.          1.34164079]]\n"
     ]
    }
   ],
   "source": [
    "print(sc.transform(data))    # it uses standardization formula ---> z = (xi-mean) / standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"left\"> 2. Normalisation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Normalisation** helps you to **scale down** your feature between **0 to 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Normalisation\n",
    "\n",
    " 1. **min-max Normalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\" align=\"center\"> Standardisation Vs Normalisation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Machine Learning **Standardisation** gives better results than **MinMaxScalar.**\n",
    "\n",
    "\n",
    "- **MinMaxScalar** is used in Deep Learning, Artificial Neural Networks, Tensor Flow, Keras need to do b/n 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_Standardization](image/1.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What happens when we apply feature scaling when there are outliers?**\n",
    "\n",
    "    1. First we need to exclude the outliers through some way.\n",
    "    \n",
    "    \n",
    "- **In few cases especially health care domain outliers are very important what happens when we scale?**\n",
    "\n",
    "    1. Use robust scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_Standardization](image/2.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_Standardization](image/3.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_Standardization](image/4.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_Standardization](image/5.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_Standardization](image/6.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1_Standardization](image/7.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "\n",
    "https://www.youtube.com/watch?v=2v_e4ITuRSs\n",
    "\n",
    "https://www.youtube.com/watch?v=mnKm3YP56PY&t=2s            Standardization Vs Normalization- Feature Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
