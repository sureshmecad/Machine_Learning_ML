{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "https://www.kaggle.com/learn/data-cleaning\n",
    "\n",
    "https://www.upgrad.com/blog/data-cleaning-techniques/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a. Handling missing values>>>>>>>>>>>>>>\n",
    "\n",
    "\n",
    "- b. Scaling and Normalization\n",
    "\n",
    "\n",
    "- c. Parsing Dates\n",
    "\n",
    "\n",
    "- d. Character Encodings\n",
    "\n",
    "\n",
    "- e. Inconsistent data entry>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing Techniques\n",
    "#### 1. Remove Irrelevant Values\n",
    "\n",
    "The first and foremost thing you should do is remove useless pieces of data from your system. Any useless or irrelevant data is the one you don’t need. It might not fit the context of your issue. \n",
    "\n",
    "You might only have to measure the **average age of your sales staff**. Then their **email address** wouldn’t be required. Another example is you might be checking to see **how many customers you contacted in a month**. In this case, you wouldn’t need the data of people you reached in a **prior month**.\n",
    "  \n",
    "  \n",
    "#### 2. Get Rid of Duplicate Values\n",
    "\n",
    "These are data points that are redundant and repetitive in the dataset that do not contribute to any new information.\n",
    "\n",
    "#### 3. Avoid Typos (and similar errors) / Inconsistent data entry\n",
    "Typos are a result of human error and can be present anywhere. You can fix typos through multiple algorithms and techniques. You can map the values and convert them into the correct spelling. Typos are essential to fix because models treat different values differently. Strings rely a lot on their spellings and cases.\n",
    "\n",
    "‘George’ is different from ‘george’ even though they have the same spelling. Similarly ‘Mike’ and ‘Mice’ are different from each other, also though they have the same number of characters. You’ll need to look for typos such as this and fix them appropriately. \n",
    "\n",
    "Another error similar to typos is of strings’ size. You might need to pad them to keep them in the same format. For example, your dataset might require you to have 5-digit numbers only. So if you have any value which only has four digits such as ‘3994’ you can add a zero in the beginning to increase its number of digits.\n",
    "#### 4. Convert Data Types\n",
    "Data types should be uniform across your dataset. A string can’t be numeric nor can a numeric be a boolean. There are several things you should keep in mind when it comes to converting data types:\n",
    "\n",
    "Keep numeric values as numerics\n",
    "Check whether a numeric is a string or not. If you entered it as a string, it would be incorrect. \n",
    "If you can’t convert a specific data value, you should enter ‘NA value’ or something of this sort. Make sure you add a warning as well to show that this particular value is wrong.\n",
    "#### 5. Take Care of Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Understand the data\n",
    "\n",
    "- All initial commands\n",
    "\n",
    "#### b. Clean the data\n",
    "\n",
    "- i) Drop unwanted features\n",
    "\n",
    "- ii) Missing Values\n",
    "\n",
    "\n",
    "#### c) Correlation Matrix (Analysis of Relationship between variables)\n",
    "\n",
    "- i) Correlation with the variable of interest (df.corr()['SepalLengthCm']\n",
    "\n",
    "\n",
    "- ii) Heatmap\n",
    "\n",
    "\n",
    "#### d) Find Outliers\n",
    "\n",
    "\n",
    "#### e) Skew and Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The steps followed for data preprocessing majorly include **handling missing and outliers** in the data.\n",
    "\n",
    " 1. Detecting missing data and outliers in the data\n",
    " 2. Understanding which approach of dealing with missing data is appropriate out of deleting, imputation by constant, mean, median, and predictive imputation\n",
    " 3. Understanding the approaches of outlier treatment which could be absolute or percentile approach \n",
    " 4. Verify if missing data and outlier treatment has modified data as required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dimensionality reduction (PCA) : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a. Univariate Analysis\n",
    "\n",
    "\n",
    "- b. Bivariate Analysis\n",
    "\n",
    "\n",
    "- c. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a. Linear Regression\n",
    "\n",
    "\n",
    "- b. Logistic Regression\n",
    "\n",
    "\n",
    "- c. Decision Tree\n",
    "\n",
    "\n",
    "- d. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation (PANDAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a. Creating, Reading and Writing\n",
    "\n",
    "\n",
    "- b. Indexing, Selecting & Assigning\n",
    "\n",
    "\n",
    "- c. Summary Functions and Maps\n",
    "\n",
    "\n",
    "- d. Grouping and Sorting\n",
    "\n",
    "\n",
    "- e. Data Types and Missing Values\n",
    "\n",
    "\n",
    "- f. Renaming and Combining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial classification methods:\n",
    "- to predict drug-drug interaction severity values\n",
    "\n",
    ">  1. SVM\n",
    "\n",
    ">  2. Naive Bayes\n",
    "\n",
    ">  3. Logistic Regression\n",
    "\n",
    ">  4. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
