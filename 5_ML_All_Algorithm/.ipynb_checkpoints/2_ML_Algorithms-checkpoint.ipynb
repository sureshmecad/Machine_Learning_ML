{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "import numpy as np                     # Linear Algebra (calculate the mean and standard deviation)\n",
    "import pandas as pd                    # manipulate data, data processing, load csv file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns                  # Visualization using seaborn\n",
    "import matplotlib.pyplot as plt        # Visualization using matplotlib\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# style\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "plt.style.use(\"fivethirtyeight\")       # Set Graphs Background style using matplotlib\n",
    "sns.set_style(\"darkgrid\")              # Set Graphs Background style using seaborn\n",
    "\n",
    "# ML model building; Pre Processing & Evaluation\n",
    "from sklearn.model_selection import train_test_split                     # split  data into training and testing sets\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge          # Linear Regression, Lasso and Ridge\n",
    "from sklearn.linear_model import LogisticRegression                      # Logistic Regression\n",
    "from sklearn.tree import DecisionTreeRegressor                           # Decision tree Regression\n",
    "from sklearn.ensemble import RandomForestClassifier                      # this will make a Random Forest Classifier\n",
    "from sklearn import svm                                                  # this will make a SVM classificaiton\n",
    "from sklearn.svm import SVC                                              # import SVC from SVM\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report      # this creates a confusion matrix\n",
    "from sklearn.metrics import roc_curve,auc                                # ROC\n",
    "from sklearn.preprocessing import StandardScaler                         # Standard Scalar\n",
    "from sklearn.model_selection import GridSearchCV                         # this will do cross validation\n",
    "\n",
    "import warnings                        # Ignore Warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the value count for different soil_types\n",
    "for i in range(10, cover.shape[1]-1):\n",
    "    j = cover.columns[i]\n",
    "    print (cover[j].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression(max_iter=1000)\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_LogReg = LogReg.predict(X_test)\n",
    "clf_accuracy.append(accuracy_score(y_test, y_pred_LogReg))\n",
    "print(accuracy_score(y_test, y_pred_LogReg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Score {:.2f} & Test Score {:.2f}\".format(LogReg.score(X_train, y_train), LogReg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n",
    "print(\"\"\"Logistic Regression \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n",
    "            np.sqrt(mean_squared_error(y_test, y_pred_LogReg)),\n",
    "            mean_squared_error(y_test, y_pred_LogReg),\n",
    "            mean_absolute_error(y_test, y_pred_LogReg),\n",
    "            r2_score(y_test, y_pred_LogReg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR = DecisionTreeRegressor()\n",
    "DTR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DTR = DTR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy.append(accuracy_score(y_test, y_pred_DTR))\n",
    "print(accuracy_score(y_test, y_pred_DTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Score {:.2f} & Test Score {:.2f}\".format(DTR.score(X_train, y_train), DTR.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model\\t\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n",
    "print(\"\"\"Decision Tree Regressor \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n",
    "            np.sqrt(mean_squared_error(y_test, y_pred_DTR)),\n",
    "            mean_squared_error(y_test, y_pred_DTR),\n",
    "            mean_absolute_error(y_test, y_pred_DTR),\n",
    "            r2_score(y_test, y_pred_DTR)))\n",
    "\n",
    "plt.scatter(y_test, y_pred_DTR)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "plt.title(\"Decision Tree Regressor\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy.append(accuracy_score(y_test, pred_rf ))\n",
    "print(accuracy_score(y_test, pred_rf ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Score {:.2f} & Test Score {:.2f}\".format(rf.score(X_train, y_train), rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n",
    "print(\"\"\"Random Forest \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n",
    "            np.sqrt(mean_squared_error(y_test, pred_rf )),\n",
    "            mean_squared_error(y_test, pred_rf ),\n",
    "            mean_absolute_error(y_test, pred_rf ),\n",
    "            r2_score(y_test, pred_rf )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. KNN (K Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "l=[i for i in range(1,11)]\n",
    "accuracy=[]\n",
    "\n",
    "for i in l:\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i, weights='distance')\n",
    "    KNN.fit(X_train, y_train)\n",
    "    pred_knn = KNN.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, pred_knn))\n",
    "\n",
    "plt.plot(l,accuracy)\n",
    "plt.title('knn_accuracy plot')\n",
    "plt.xlabel('neighbors')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()\n",
    "\n",
    "print(max(accuracy))\n",
    "\n",
    "clf_accuracy.append(max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n",
    "print(\"\"\"Random Forest \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n",
    "            np.sqrt(mean_squared_error(y_test, pred_rf )),\n",
    "            mean_squared_error(y_test, pred_rf ),\n",
    "            mean_absolute_error(y_test, pred_rf ),\n",
    "            r2_score(y_test, pred_rf )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "reg_xgb = xgboost.XGBClassifier(max_depth=7)\n",
    "reg_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting X_test\n",
    "y_pred_xgb = reg_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Score {:.2f} & Test Score {:.2f}\".format(reg_xgb.score(X_train,y_train),reg_xgb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy.append(accuracy_score(y_test, y_pred_xgb))\n",
    "print(accuracy_score(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n",
    "print(\"\"\"XGBClassifier \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n",
    "            np.sqrt(mean_squared_error(y_test, pred_rf )),\n",
    "            mean_squared_error(y_test, pred_rf ),\n",
    "            mean_absolute_error(y_test, pred_rf ),\n",
    "            r2_score(y_test, pred_rf )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy.append(accuracy_score(y_test, pred_nb))\n",
    "print(accuracy_score(y_test, pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Score {:.2f} & Test Score {:.2f}\".format(nb.score(X_train,y_train),nb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model\\t\\t\\t RMSE \\t\\t MSE \\t\\t MAE \\t\\t R2\")\n",
    "print(\"\"\"Naive Bayes Classifier \\t {:.2f} \\t\\t {:.2f} \\t\\t{:.2f} \\t\\t{:.2f}\"\"\".format(\n",
    "            np.sqrt(mean_squared_error(y_test, pred_nb )),\n",
    "            mean_squared_error(y_test, pred_nb ),\n",
    "            mean_absolute_error(y_test, pred_nb ),\n",
    "            r2_score(y_test, pred_nb )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification Report\n",
    "print(classification_report(y_test, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cf_matrix = confusion_matrix(y_test, pred_rf)\n",
    "print('Confusion Matrix \\n',cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(cf_matrix, cmap='coolwarm', annot=True, linewidth=1, fmt=\"d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Summary :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list=['Logistic Regression','Decision Tree','Random Forest','KNN','xgboost','nbayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_accuracy1 = [0.7116597678201079,0.9381255217163068,0.9471184048604597,0.8405376797500925,0.8977134841613383,0.2682719034792561]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "sns.barplot(x=clf_accuracy1, y=classifier_list)\n",
    "plt.grid()\n",
    "plt.xlabel('accuracy')\n",
    "plt.ylabel('classifier')\n",
    "plt.title('classifier vs accuracy plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogReg, DTR, rf, KNN, reg_xgb, nb]\n",
    "names = ['Logistic Regression','Decision Tree','Random Forest','KNN','xgboost','nbayes']\n",
    "rmses = []\n",
    "\n",
    "for model in models:\n",
    "    rmses.append(np.sqrt(mean_squared_error(y_test, model.predict(X_test))))\n",
    "\n",
    "x = np.arange(len(names)) \n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "rects = ax.bar(x, rmses, width)\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_xlabel('Models')\n",
    "\n",
    "ax.set_title('RMSE with Different Algorithms')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(names, rotation=45)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Loan_ID': test['Loan_ID'], 'Loan_Status': y_pred_test})\n",
    "submission.to_csv('Predict Loan.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
